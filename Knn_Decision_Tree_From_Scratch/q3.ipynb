{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(train_data_frm):\n",
    "    #print(train_data_frm.columns.values)\n",
    "    train_data_frm = DropColumns(train_data_frm)\n",
    "    train_data_frm = FillMissingValues(train_data_frm)\n",
    "    df = train_data_frm\n",
    "    nan_rows = df[df.isnull().T.any().T]\n",
    "    return train_data_frm\n",
    "\n",
    "#train_data= pd.read_csv(\"train.csv\")\n",
    "#PrepareData(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillMissingValues(train_data_frm):\n",
    "    \n",
    "    fill_col=['YrSold','MoSold','MiscVal','PoolArea','ScreenPorch',\n",
    "              '3SsnPorch','EnclosedPorch','OpenPorchSF','WoodDeckSF',\n",
    "              'GarageArea','GarageCars','GarageYrBlt','Fireplaces',\n",
    "              'TotRmsAbvGrd','Kitchen','Bedroom','LotFrontage','LotArea',\n",
    "              'YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2',\n",
    "              'BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF',\n",
    "              'GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath']\n",
    "    for val in train_data_frm.columns.values:\n",
    "        if(val in fill_col):\n",
    "            train_data_frm[val] = train_data_frm[val].fillna((train_data_frm[val].mean()))\n",
    "        else:\n",
    "            train_data_frm[val] = train_data_frm[val].fillna((train_data_frm[val].mode()[0]))      \n",
    "    return train_data_frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropColumns(train_data_frm):\n",
    "    train_data_frm = train_data_frm.drop('Alley', axis=1)\n",
    "    train_data_frm = train_data_frm.drop('PoolQC', axis=1)\n",
    "    train_data_frm = train_data_frm.drop('Fence', axis=1)\n",
    "    train_data_frm = train_data_frm.drop('MiscFeature', axis=1)\n",
    "    train_data_frm = train_data_frm.drop('Id', axis=1)\n",
    "\n",
    "    return train_data_frm\n",
    "\n",
    "def check_categorical(column):\n",
    "        fill_col=['YrSold','MoSold','MiscVal','PoolArea','ScreenPorch',\n",
    "              '3SsnPorch','EnclosedPorch','OpenPorchSF','WoodDeckSF',\n",
    "              'GarageArea','GarageCars','GarageYrBlt','Fireplaces',\n",
    "              'TotRmsAbvGrd','Kitchen','Bedroom','LotFrontage','LotArea',\n",
    "              'YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2',\n",
    "              'BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF',\n",
    "              'GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath']\n",
    "        if(column in fill_col):\n",
    "            return False\n",
    "        return True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillWithUniqueCat(train_data,Col):\n",
    "    # print( \" in FillWithUniqueCat \")\n",
    "    df  = train_data[Col]\n",
    "    lis = df.values\n",
    "    mylist = list(set(lis))\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillWithUniqueContinuous(train_data,col):\n",
    "    # print(\" in FillWithUniqueContinuous \")\n",
    "    df  = train_data[col]\n",
    "    lis = df.values\n",
    "    lis = list(set(lis))\n",
    "    val = 0\n",
    "    lis1=[]\n",
    "    if(len(lis) == 1):\n",
    "        return lis\n",
    "    for i in range(len(lis)-1):\n",
    "        lis1.append((lis[i]+lis[i+1])/2)\n",
    "    return  lis1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dtree_regressor :\n",
    "    \n",
    "    def __init__(self):\n",
    "        name=\"\"\n",
    "        \n",
    "    sub_tree =  dict()\n",
    "    \n",
    "    def train(self,filename):\n",
    "        train_data = pd.read_csv(filename)\n",
    "        train_data = PrepareData(train_data)\n",
    "        self.sub_tree = self.DecisionTree(train_data, counter = 0,\n",
    "                     min_samples = 2, max_depth = 5)\n",
    "        \n",
    "        \n",
    "    def test(self,filename):\n",
    "        test_data = pd.read_csv(filename)\n",
    "        test_data = PrepareData(test_data)\n",
    "        return [self.classify_example(row, self.sub_tree) for i, row in test_data.iterrows()]\n",
    "    \n",
    "    def make_dictionary(self,train_data,NewDict):\n",
    "        #print(\" in make dic \")\n",
    "        for col in train_data.columns.values:\n",
    "            if check_categorical(col):\n",
    "                NewDict[col] = FillWithUniqueCat(train_data,col)\n",
    "            else :\n",
    "                NewDict[col] = FillWithUniqueContinuous(train_data,col)\n",
    "        #print(self.NewDict)\n",
    "        return NewDict\n",
    "        \n",
    "    \n",
    "    \n",
    "    def FindMeanSquareError(self,train_data ,  attribute,col):\n",
    "        left  = train_data[train_data[col] == attribute]\n",
    "        right = train_data[train_data[col] != attribute]\n",
    "        mleft = left['SalePrice'].mean()\n",
    "        mright= right['SalePrice'].mean()\n",
    "        summ  = 0\n",
    "        summ1 = 0\n",
    "        \n",
    "        for val in left['SalePrice']:\n",
    "            summ=summ+(val-mleft)*(val-mleft)\n",
    "        \n",
    "        for val in right['SalePrice']:\n",
    "            summ1=summ1+(val-mright)*(val-mright)\n",
    "        countUp = left.shape[1]\n",
    "        countDown = right.shape[1]\n",
    "        over_all_mean =  ((countUp*summ)/(countUp + countDown))  +  ((countDown*summ1)/(countUp + countDown))\n",
    "        #print(\" mean = \")\n",
    "        #print(over_all_mean)\n",
    "        return [over_all_mean , col, attribute] \n",
    "            \n",
    "    \n",
    "    def FindUpAndDown(self,train_data,lis,col):\n",
    "        #print(\" in FindUpAndDown \")\n",
    "        MSE = []\n",
    "        i=0\n",
    "        for attribute in lis:\n",
    "                MSE.append(self.FindMeanSquareError(train_data,attribute,col))\n",
    "        # MSE = [self.FindMeanSquareError(train_data, attribute, col) for attribute in lis].sort()[0]\n",
    "        #print(MSE)    \n",
    "        MSE.sort()\n",
    "        #print(MSE[0])\n",
    "        return MSE[0]\n",
    "    \n",
    "\n",
    "    def FindMeanSquareErrorNUm(self,train_data, left, right,col,x):\n",
    "        meanl = left['SalePrice'].mean()\n",
    "        meanr = left['SalePrice'].mean()\n",
    "        summ =0\n",
    "        for i in left['SalePrice']:\n",
    "            summ = summ + (i -meanl)*(i - meanl)   \n",
    "        summ1=0\n",
    "        for i in right['SalePrice']:\n",
    "            summ1 = summ1 + (i -meanr)*(i - meanr)\n",
    "        total = len(left) + len(right)\n",
    "        overAllMean = ((summ*len(left))/total) + ((summ1*len(right))/total)\n",
    "        #print(\" mean num = \")\n",
    "        #print(overAllMean)\n",
    "        \n",
    "        return [overAllMean,col, x] \n",
    "            \n",
    "    \n",
    "    def FindUpAndDownForNUm(self,train_data, lis, col):\n",
    "        #print(\" in FindUpAndDownForNUm \")\n",
    "\n",
    "        MSE = []\n",
    "        i=0\n",
    "       # print(\" lis = \")\n",
    "        #print(len(lis))\n",
    "        for i in range(len(lis)):\n",
    "            left = train_data[train_data[col] <= lis[i]]\n",
    "            right= train_data[train_data[col] > lis[i]]\n",
    "            MSE.append(self.FindMeanSquareErrorNUm(train_data, left, right,col,lis[i]))\n",
    "            i=i+1\n",
    "            \n",
    "        MSE.sort()\n",
    "        #print(len(MSE))\n",
    "        #print(MSE[0])\n",
    "        #print(MSE)\n",
    "        return MSE[0]\n",
    "    ## alright*****************************        \n",
    "    def check_purity(self,data):\n",
    "        label_column = data['SalePrice'].values\n",
    "        unique_classes = np.unique(label_column)\n",
    "        if len(unique_classes) == 1:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def make_split(self,train_data):\n",
    "       # print(\"in make split\")\n",
    "        val = []\n",
    "        NewDict = dict()\n",
    "        NewDict = self.make_dictionary(train_data,NewDict )\n",
    "        #print(\" dict size = \")\n",
    "        #print(len(NewDict))\n",
    "        column = train_data.columns.values\n",
    "        #print(column)\n",
    "        for col in column:\n",
    "            if col == 'SalePrice':\n",
    "                continue\n",
    "            if check_categorical(col):\n",
    "                lis = NewDict[col]\n",
    "                val.append(self.FindUpAndDown(train_data , lis, col))\n",
    "            else :\n",
    "                lis = NewDict[col]\n",
    "                val.append(self.FindUpAndDownForNUm(train_data , lis, col))\n",
    "        val.sort()\n",
    "        return val[0]\n",
    "    \n",
    "    \n",
    "    def split_data(self,data , col , attribute):\n",
    "        if check_categorical(col):\n",
    "            data_below = data[data[col] == attribute]\n",
    "            data_above = data[data[col] != attribute]\n",
    "        else:\n",
    "            data_below = data[data[col] <= attribute]\n",
    "            data_above = data[data[col] > attribute]\n",
    "        return data_below, data_above\n",
    "    \n",
    "    #*********\n",
    "    def classify_data(self,data):\n",
    "        label_column = data['SalePrice']\n",
    "        unique_classes, counts_unique_classes = np.unique(\n",
    "            label_column,return_counts = True)\n",
    "        index = counts_unique_classes.argmax()\n",
    "        classification = unique_classes[index]\n",
    "        return classification\n",
    "    \n",
    "    \n",
    "    \n",
    "    def DecisionTree(self,train_data, counter = 0,\n",
    "                     min_samples = 2, max_depth = 5):\n",
    "        print(\" IN decision tree \")\n",
    "        if counter == 0:\n",
    "            global col \n",
    "            col = train_data.columns\n",
    "            data = train_data\n",
    "        else:\n",
    "            data = train_data\n",
    "            \n",
    "        if (self.check_purity(data)) or (data.shape[1] < min_samples) or (counter == max_depth):\n",
    "            classification = self.classify_data(data)\n",
    "            return classification\n",
    "        else :\n",
    "            counter+=1\n",
    "            print(\" data \")\n",
    "            print(data.shape)\n",
    "            mean, c , attribute = self.make_split(data)\n",
    "            print(\" mean c attribute \")\n",
    "            print(mean)\n",
    "            print(c)\n",
    "            print(attribute)\n",
    "            data_below, data_above = self.split_data(data, c, attribute)\n",
    "            feature_name = c\n",
    "            question = \"{} <= {}\".format(feature_name,attribute)\n",
    "            sub_tree = {question : []}\n",
    "            yes_answer = self.DecisionTree(data_below, counter, \n",
    "                                      min_samples,max_depth)\n",
    "            no_answer = self.DecisionTree(data_above, counter, \n",
    "                                     min_samples, max_depth)\n",
    "            if yes_answer == no_answer:\n",
    "                self.sub_tree = yes_answer\n",
    "            else :\n",
    "                sub_tree[question].append(yes_answer)\n",
    "                sub_tree[question].append(no_answer)\n",
    "\n",
    "            return sub_tree\n",
    "    \n",
    "    \n",
    "    def classify_example(self, example, tree):\n",
    "        question = list(tree.keys())[0]\n",
    "        feature_name, comparison_operator, value = question.split(\" \")\n",
    "        if(check_categorical(feature_name)):\n",
    "            if example[feature_name] == value:\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "\n",
    "        else:\n",
    "            if example[feature_name] <=float(value):\n",
    "                answer = tree[question][0]\n",
    "            else :\n",
    "                answer = tree[question][1]\n",
    "\n",
    "        if not isinstance(answer, dict):\n",
    "            return answer\n",
    "\n",
    "        else:\n",
    "            residual_tree = answer\n",
    "            return self.classify_example(example, residual_tree)\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IN decision tree \n",
      " data \n",
      "(1000, 76)\n",
      " mean c attribute \n",
      "2174739774483.6956\n",
      "ExterQual\n",
      "TA\n",
      " IN decision tree \n",
      " data \n",
      "(616, 76)\n",
      " mean c attribute \n",
      "468520185524.20215\n",
      "OverallQual\n",
      "7\n",
      " IN decision tree \n",
      " data \n",
      "(63, 76)\n",
      " mean c attribute \n",
      "61285917639.34426\n",
      "LandSlope\n",
      "Sev\n",
      " IN decision tree \n",
      " data \n",
      "(2, 76)\n",
      " mean c attribute \n",
      "0.0\n",
      "BedroomAbvGr\n",
      "2\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(61, 76)\n",
      " mean c attribute \n",
      "47121565583.05556\n",
      "GarageType\n",
      "Detchd\n",
      " IN decision tree \n",
      " data \n",
      "(16, 76)\n",
      " mean c attribute \n",
      "1926499487.1794868\n",
      "BsmtFinType1\n",
      "LwQ\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(45, 76)\n",
      " mean c attribute \n",
      "34432955388.396774\n",
      "TotalBsmtSF\n",
      "1352\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(553, 76)\n",
      " mean c attribute \n",
      "322962396673.79266\n",
      "GarageFinish\n",
      "Unf\n",
      " IN decision tree \n",
      " data \n",
      "(375, 76)\n",
      " mean c attribute \n",
      "192389250291.23663\n",
      "CentralAir\n",
      "N\n",
      " IN decision tree \n",
      " data \n",
      "(54, 76)\n",
      " mean c attribute \n",
      "13489694471.454548\n",
      "BedroomAbvGr\n",
      "4\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(321, 76)\n",
      " mean c attribute \n",
      "147560539265.49857\n",
      "OverallQual\n",
      "8\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(178, 76)\n",
      " mean c attribute \n",
      "80927096004.09038\n",
      "Neighborhood\n",
      "NridgHt\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(177, 76)\n",
      " mean c attribute \n",
      "67013338324.79012\n",
      "OverallQual\n",
      "6\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(384, 76)\n",
      " mean c attribute \n",
      "1145529993042.8582\n",
      "KitchenQual\n",
      "Ex\n",
      " IN decision tree \n",
      " data \n",
      "(64, 76)\n",
      " mean c attribute \n",
      "304544352924.625\n",
      "Neighborhood\n",
      "NoRidge\n",
      " IN decision tree \n",
      " data \n",
      "(4, 76)\n",
      " mean c attribute \n",
      "1033062500.0\n",
      "Exterior1st\n",
      "VinylSd\n",
      " IN decision tree \n",
      " data \n",
      "(2, 76)\n",
      " mean c attribute \n",
      "0.0\n",
      "BedroomAbvGr\n",
      "2\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(2, 76)\n",
      " mean c attribute \n",
      "0.0\n",
      "BsmtExposure\n",
      "Av\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(60, 76)\n",
      " mean c attribute \n",
      "207589886350.40625\n",
      "BedroomAbvGr\n",
      "4\n",
      " IN decision tree \n",
      " data \n",
      "(12, 76)\n",
      " mean c attribute \n",
      "42054274835.33333\n",
      "BsmtExposure\n",
      "No\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(48, 76)\n",
      " mean c attribute \n",
      "113711963803.23738\n",
      "BsmtQual\n",
      "Ex\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(320, 76)\n",
      " mean c attribute \n",
      "569917187400.7097\n",
      "OverallQual\n",
      "8\n",
      " IN decision tree \n",
      " data \n",
      "(100, 76)\n",
      " mean c attribute \n",
      "132320307648.5179\n",
      "Neighborhood\n",
      "NoRidge\n",
      " IN decision tree \n",
      " data \n",
      "(16, 76)\n",
      " mean c attribute \n",
      "13595116666.66667\n",
      "Exterior1st\n",
      "BrkFace\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(84, 76)\n",
      " mean c attribute \n",
      "92603404951.61017\n",
      "RoofStyle\n",
      "Gable\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(220, 76)\n",
      " mean c attribute \n",
      "331507442616.6697\n",
      "OverallQual\n",
      "10\n",
      " IN decision tree \n",
      " data \n",
      "(2, 76)\n",
      " mean c attribute \n",
      "0.0\n",
      "BedroomAbvGr\n",
      "3\n",
      " IN decision tree \n",
      " IN decision tree \n",
      " IN decision tree \n",
      " data \n",
      "(218, 76)\n",
      " mean c attribute \n",
      "249787423239.52826\n",
      "ExterQual\n",
      "Fa\n",
      " IN decision tree \n",
      " IN decision tree \n",
      "{'ExterQual <= TA': [{'OverallQual <= 7': [{'LandSlope <= Sev': [{'BedroomAbvGr <= 2': [302000, 375000]}, {'GarageType <= Detchd': [{'BsmtFinType1 <= LwQ': [169500, 116900]}, {'TotalBsmtSF <= 1352': [176000, 82500]}]}]}, {'GarageFinish <= Unf': [{'CentralAir <= N': [{'BedroomAbvGr <= 4': [145000, 79000]}, {'OverallQual <= 8': [359100, 135000]}]}, {'Neighborhood <= NridgHt': [342643, {'OverallQual <= 6': [140000, 129000]}]}]}]}, {'KitchenQual <= Ex': [{'Neighborhood <= NoRidge': [{'Exterior1st <= VinylSd': [{'BedroomAbvGr <= 2': [466500, 403000]}, {'BsmtExposure <= Av': [745000, 755000]}]}, {'BedroomAbvGr <= 4': [{'BsmtExposure <= No': [269500, 345000]}, {'BsmtQual <= Ex': [315000, 178400]}]}]}, {'OverallQual <= 8': [{'Neighborhood <= NoRidge': [{'Exterior1st <= BrkFace': [430000, 290000]}, {'RoofStyle <= Gable': [212000, 275000]}]}, {'OverallQual <= 10': [{'BedroomAbvGr <= 3': [325000, 625000]}, {'ExterQual <= Fa': [39300, 190000]}]}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = dtree_regressor()\n",
    "train_data = tree.train(\"train.csv\")\n",
    "print(tree.sub_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price = tree.test('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_price = [tree.classify_example(row, tree.sub_tree) for i, row in predicted_price.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 39300,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 79000,\n",
       " 315000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 315000,\n",
       " 135000,\n",
       " 79000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 178400,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 79000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 39300,\n",
       " 315000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 79000,\n",
       " 135000,\n",
       " 79000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 315000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 178400,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 315000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 315000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 79000,\n",
       " 190000,\n",
       " 190000,\n",
       " 79000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 315000,\n",
       " 190000,\n",
       " 135000,\n",
       " 79000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 79000,\n",
       " 135000,\n",
       " 135000,\n",
       " 178400,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 39300,\n",
       " 190000,\n",
       " 178400,\n",
       " 129000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 178400,\n",
       " 315000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 315000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 79000,\n",
       " 190000,\n",
       " 135000,\n",
       " 79000,\n",
       " 190000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 178400,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 315000,\n",
       " 315000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 315000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 315000,\n",
       " 129000,\n",
       " 190000,\n",
       " 79000,\n",
       " 79000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 79000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 315000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 79000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 79000,\n",
       " 79000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 135000,\n",
       " 79000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 315000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 79000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 129000,\n",
       " 79000,\n",
       " 190000,\n",
       " 79000,\n",
       " 190000,\n",
       " 190000,\n",
       " 178400,\n",
       " 135000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 315000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 79000,\n",
       " 315000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 135000,\n",
       " 79000,\n",
       " 135000,\n",
       " 135000,\n",
       " 178400,\n",
       " 135000,\n",
       " 79000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 190000,\n",
       " 135000,\n",
       " 129000,\n",
       " 129000,\n",
       " 190000,\n",
       " 39300,\n",
       " 79000,\n",
       " 135000,\n",
       " 190000,\n",
       " 190000,\n",
       " 129000,\n",
       " 190000,\n",
       " 190000,\n",
       " 135000,\n",
       " 135000,\n",
       " 129000,\n",
       " 190000,\n",
       " 135000]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128000, 124900, 191000, 144000, 231500, 135750, 149700,  85000,\n",
       "       196000, 155000, 146500, 171750, 385000, 139500, 136000, 446261,\n",
       "       135000, 155000, 117500, 145000, 168500, 301000, 394617, 104900,\n",
       "        80000, 135000, 120000, 164500, 143000, 115000, 157500, 272000,\n",
       "       240000, 135000, 251000, 130250, 197500, 181134, 214500, 115000,\n",
       "       213490, 124000, 172500, 160000, 200000, 150000, 142500, 149900,\n",
       "       129500, 169000, 237000, 222500, 162500,  93500, 153500, 169000,\n",
       "       144500,  60000, 325000, 143000, 305900, 197900,  96500, 187500,\n",
       "       221000, 113000, 137000, 107000, 135900, 192000, 189000, 110000,\n",
       "       241000, 180000, 128000, 149000, 136500, 424870,  62383, 314813,\n",
       "       179900, 339750, 110000, 139000, 131000, 214000, 170000, 438780,\n",
       "       317000, 185000, 175000, 188700, 381000, 110000, 227680, 134900,\n",
       "       108480, 110000, 167900, 187500, 276000, 199900, 244000, 171900,\n",
       "       184000, 173500, 117000, 144000, 225000, 239000, 239000, 235000,\n",
       "       312500, 132000, 132500, 348000, 130500, 168500, 112500,  68400,\n",
       "       139000, 181000, 169500, 156000, 124500, 239900, 245000, 119000,\n",
       "       121600, 255000, 174000, 116000, 119500, 127500, 200000,  97000,\n",
       "       224500, 145250, 151400, 340000, 228500, 240000, 181000, 143000,\n",
       "       194000, 185000, 162000,  95000, 245350, 280000, 115000, 160000,\n",
       "       216500, 130500, 136905, 164700, 412500, 208300, 118964, 129000,\n",
       "       139400, 135000, 141000, 118000, 134500, 157500,  80500, 111000,\n",
       "       133000, 281000, 230000,  85000, 117000, 183500, 128950, 138887,\n",
       "       392000, 164990,  93000, 230000, 303477, 180000, 167240, 124000,\n",
       "       159000, 164000, 155000, 313000, 220000, 163990, 290000, 124000,\n",
       "        99900, 228500, 156500, 196000, 105000, 156000, 165000, 119500,\n",
       "       155000, 142000, 207500,  98600, 149000, 147000, 235000, 315750,\n",
       "       213500, 611657,  92000, 118500, 200000, 131500, 153900,  97000,\n",
       "       239000, 194700, 100000, 170000, 144000, 261500, 148000, 175000,\n",
       "       150500, 262500, 130000, 241500, 197000, 171000, 258000, 137500,\n",
       "       179900, 187000, 179600, 171000, 140000,  84500, 110000, 158000,\n",
       "       189000, 217000,  93000, 268000, 213000, 190000, 244000, 402861,\n",
       "       385000, 148500, 110000, 119000, 107400, 263000,  79900,  97500,\n",
       "       229456, 282922, 158000, 103000, 242000, 140000, 140000, 152000,\n",
       "       119000, 144500, 179540, 140000, 119200, 361919, 192500, 211000,\n",
       "       110000, 167000, 191000, 184000, 153000, 215000, 248000, 501837,\n",
       "       190000, 215000,  98000, 128000, 179900, 136500,  91300, 110500,\n",
       "       115000, 148000,  91000, 160000, 180500, 204750,  75000, 336000,\n",
       "       440000, 207000, 250000, 168500, 127000, 107000, 165000, 178900,\n",
       "       146000, 295493, 135000, 116050, 155000, 177000, 136500, 132000,\n",
       "       145000, 170000, 141000, 122500, 150000, 113000, 113000,  79500,\n",
       "       127000, 135000, 158000, 229000, 216837, 115000, 187100, 102000,\n",
       "       145000, 115000, 220000,  87000,  88000, 200000, 250000, 187500,\n",
       "       176000, 140000, 189000, 185000, 149500, 130000, 133000, 104000,\n",
       "       108000, 186500,  87000, 109500, 100000, 120000,  91000, 172500,\n",
       "       173900, 179665, 192000, 286000, 125500, 226700, 127500, 119500,\n",
       "       185000, 163000, 191000, 118500, 206000, 126000, 260000, 161000,\n",
       "       148000, 160000, 185000,  55000, 212900, 263435, 275000,  85400,\n",
       "       170000, 180000, 187750, 153500, 226000, 142600, 115000, 190000,\n",
       "       175000, 114500, 254000, 233170, 175000, 248328,  91500, 215200,\n",
       "       197000, 157000, 228000, 319900, 181000, 266000, 217000,  75500,\n",
       "       140000, 350000, 144152, 181000, 230000, 208500, 151000, 194000,\n",
       "        88000, 117000, 185000, 193500, 155900, 141000, 138800, 148800,\n",
       "       165000, 145000, 233000, 142000, 260400, 274300, 240000, 120000,\n",
       "       100000, 230000, 253000, 198500, 215000, 152000,  35311, 161000,\n",
       "       120000, 260000, 159434,  87500, 219500, 266500, 136000, 226000,\n",
       "       132500, 124500, 194500, 206900, 154500, 139000, 230000,  61000,\n",
       "       167500, 128500, 187500, 165400, 252678, 147400, 248000,  86000,\n",
       "        64500, 160000, 204000, 153000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40162.87391304348"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(label[1].values, predicted_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error With Sklearn Decision Tree :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Data \n",
      " Train Data \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    354000\n",
       "1    378500\n",
       "2    153500\n",
       "3    173733\n",
       "4    127000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from pprint import pprint\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "TrainData  = pd.read_csv(\"train.csv\")\n",
    "TrainLabel = TrainData['SalePrice']\n",
    "del TrainData['SalePrice']\n",
    "TestData   = pd.read_csv(\"test.csv\")\n",
    "print(\" Test Data \")\n",
    "TestData.head()\n",
    "print(\" Train Data \")\n",
    "TrainLabel.head()\n",
    "#regression = DecisionTreeRegressor(random_state = 0)\n",
    "#regression.fit(TrainData , TrainLabel)\n",
    "#predicted_decision = regression.predict(TestData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2 Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37930356091795503"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, r2_score\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "r2_score(label[1].values, predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
