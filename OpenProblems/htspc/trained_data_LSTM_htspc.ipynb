{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhLaT_qMfeX7",
        "colab_type": "code",
        "outputId": "879c0f6a-9b5b-4aa2-b740-a24d893d6aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "!pip install demoji\n",
        "!pip install emoji\n",
        "!pip install Unidecode\n",
        "import pandas as pd\n",
        "import sys\n",
        "import string  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import cv2\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.metrics import precision_score, recall_score, r2_score\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from sklearn import datasets, svm, metrics\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "from keras.utils import to_categorical\n",
        "import demoji\n",
        "import emoji\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Bidirectional,Dense,Conv1D,Flatten,LSTM,GlobalMaxPooling1D,Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting demoji\n",
            "  Downloading https://files.pythonhosted.org/packages/da/0b/d008f26ebbfd86d21117267e627f2f7359c76e5ecbeba08d8f631f4092c4/demoji-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.21.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from demoji) (46.1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
            "Installing collected packages: colorama, demoji\n",
            "Successfully installed colorama-0.4.3 demoji-0.2.1\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=5bfaeb3ee6d91bacd0ffe9b2fecf94f7080bdea740128c0a27f464effda20612\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245kB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.1.1\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZe6nj1hq6LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Data_4/1fe720be-90e4-4e06-9b52-9de93e0ea937_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBNRBsnqrvOh",
        "colab_type": "code",
        "outputId": "bdf1d5f4-6bf6-43aa-9d37-d983d41c7678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "Label = df['labels']\n",
        "df[df.labels == 0].head(100)\n",
        "df[df.labels == 0].head(100)\n",
        "print(df[0:85])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 text  labels\n",
            "0   @realDonaldTrump This is one of the worst time...       0\n",
            "1   How about the crowd in Oval in today's #AUSvIN...       1\n",
            "2   @skroskz @shossy2 @JoeBiden Biden &amp; his so...       0\n",
            "3   #etsy shop: Benedict Donald so called presiden...       1\n",
            "4   @realDonaldTrump Good build a wall around Arka...       0\n",
            "..                                                ...     ...\n",
            "80  @cdnfp @SecPompeo @StateDept @realDonaldTrump ...       0\n",
            "81  #DhoniKeepTheGlove  @ICC @cricketworldcup   I ...       1\n",
            "82  üòÇForget Parsees Save üòÇ #CongBachaoRahulHatao #...       0\n",
            "83  Kamala Harris: Trump is a 'clear and present t...       0\n",
            "84  Some Cars its wiser to stay away from!!  üò£üòîüò•.....       1\n",
            "\n",
            "[85 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2q6DpBQrxm8",
        "colab_type": "code",
        "outputId": "2477db4e-71d9-4c6c-895f-8e2c94924f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "example1 = BeautifulSoup(df.text[78], 'lxml')\n",
        "print(Label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       0\n",
            "1       1\n",
            "2       0\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "5261    1\n",
            "5262    1\n",
            "5263    1\n",
            "5264    0\n",
            "5265    1\n",
            "Name: labels, Length: 5266, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj7_CraLs-ZD",
        "colab_type": "code",
        "outputId": "51e06ffa-6e5d-4306-8b3e-57965f3026ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "t = example1.get_text()\n",
        "a = df[84:85]\n",
        "print(a)\n",
        "example2 = BeautifulSoup(df.text[84], 'lxml')\n",
        "print(example2.get_text())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 text  labels\n",
            "84  Some Cars its wiser to stay away from!!  üò£üòîüò•.....       1\n",
            "Some Cars its wiser to stay away from!!  üò£üòîüò•... üòÖüòÅüòÅüòÅüòÅüòè  #fear #not #eyes #open #peeled #set #up #enemy #truly #beware #liars #molestors #rapist #all #shit #eat #eaters #tire #not #solid #soldier #God #first https://t.co/AEILxDvfFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkhJx9Bz4LYN",
        "colab_type": "code",
        "outputId": "1a4d67d4-a0a5-4788-b78f-620e7ae4c4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import demoji\n",
        "import emoji\n",
        "demoji.download_codes()\n",
        "dictionary = demoji.findall(t)\n",
        "print(emoji.demojize(t))\n",
        "from emoji.unicode_codes import UNICODE_EMOJI\n",
        "unicode_text = t.encode('unicode-escape')\n",
        "print(unicode_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emoji data ...\n",
            "... OK (Got response in 0.11 seconds)\n",
            "Writing emoji data to /root/.demoji/codes.json ...\n",
            "... OK\n",
            "Happy #JohnMCainDay #JohnMcCainDayJune14th #JohnMcCainAmericanHero :United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States::United_States:Also #FuckTrump\n",
            "b'Happy #JohnMCainDay #JohnMcCainDayJune14th #JohnMcCainAmericanHero \\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8\\\\U0001f1fa\\\\U0001f1f8Also #FuckTrump'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpbyc_KktF-B",
        "colab_type": "code",
        "outputId": "5cc8ed0e-4c78-4167-f5c7-4e0fc3b658e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "re.sub(r'@[A-Za-z0-9]+','',df.text[343])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"  #Sad I saw a portapotty full to the top at work today &amp; thought of you trump &amp; I realized something. The full portapotty has less shit in it than you &amp; it does it's job well. You could learn from that. #trumpdeathcamps  #Trump2020 #TrumpTrain #fucktrump  #Fucktrump\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2iNmCBXtt65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "ps = PorterStemmer() \n",
        "def tweet_cleaner(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
        "    # I will tokenize and join together to remove unneccessary white spaces\n",
        "    words = tok.tokenize(lower_case)\n",
        "    wordss = []\n",
        "    for w in wordss: \n",
        "      words.append(lemmatizer.lemmatize(w)) \n",
        "    S = (\" \".join(words)).strip()\n",
        "    return S\n",
        "\n",
        "def PreProcessing(Data):\n",
        "    #print('shape - ', Data.shape[0])\n",
        "    #print(Data.iloc[0,:])\n",
        "    for i in range(Data.shape[0]):\n",
        "        before = Data\n",
        "        #remove numbers\n",
        "        feature = Data.iloc[i,:]\n",
        "\n",
        "        feature = ''.join(i for i in feature if not i.isdigit())\n",
        "        #remove punctuation\n",
        "        exc = set(string.punctuation)\n",
        "        feature = ''.join(ch for ch in feature if ch not in exc)\n",
        "        #print(feature)\n",
        "        #encoding to ascii\n",
        "        feature = unidecode(feature)\n",
        "        feature = feature.lower()\n",
        "        #extra space\n",
        "        feature = feature.strip()\n",
        "        feature.encode('ascii', 'ignore').decode('ascii')\n",
        "        #tokenize\n",
        "        tokenizer = RegexpTokenizer(\"\\w+|\\d\\.]+|\\S+\")\n",
        "        tokens = tokenizer.tokenize(feature)\n",
        "        # stopWords = set(stopwords.words('english'))\n",
        "        # New_Data = [w for w in tokens if not w in tokens]\n",
        "        Data.iloc[i,:] = ' '.join([str(w) for w in tokens])\n",
        "    return Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhw5kYaGmPjr",
        "colab_type": "code",
        "outputId": "172c8171-82ee-485b-d0d3-de2eef4da083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testing = df.text[:100]\n",
        "test_result = []\n",
        "for t in testing:\n",
        "    test_result.append(tweet_cleaner(t))\n",
        "len(test_result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr5dhGTcEBPj",
        "colab_type": "code",
        "outputId": "75313bab-ca73-4478-b815-f6fde9e7bf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        " test_result = pd.DataFrame(test_result, columns=['text'])\n",
        " test_result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is one of the worst times to be american ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how about the crowd in oval in today s ausvind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>biden his son hunter took advantage of their p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>etsy shop benedict donald so called president ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>good build a wall around arkansas fucktrump fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>some much needed clarification after trumps un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>is putin s puppet trumpsworsethannixon trumpmu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>narendra modi sir please look into bihar child...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>but he didn t trumpsworsethannixon trumpisatra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>democrats to scrutinize ex lobbyist s role in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text\n",
              "0   this is one of the worst times to be american ...\n",
              "1   how about the crowd in oval in today s ausvind...\n",
              "2   biden his son hunter took advantage of their p...\n",
              "3   etsy shop benedict donald so called president ...\n",
              "4   good build a wall around arkansas fucktrump fu...\n",
              "..                                                ...\n",
              "95  some much needed clarification after trumps un...\n",
              "96  is putin s puppet trumpsworsethannixon trumpmu...\n",
              "97  narendra modi sir please look into bihar child...\n",
              "98  but he didn t trumpsworsethannixon trumpisatra...\n",
              "99  democrats to scrutinize ex lobbyist s role in ...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQOt5VXt0WFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_result = PreProcessing(test_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MKlLPNHn35u",
        "colab_type": "code",
        "outputId": "e4bcece6-9010-4821-9569-1a75b4ee00f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "test_result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is one of the worst times to be american ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how about the crowd in oval in today s ausvind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>biden his son hunter took advantage of their p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>etsy shop benedict donald so called president ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>good build a wall around arkansas fucktrump fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>some much needed clarification after trumps un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>is putin s puppet trumpsworsethannixon trumpmu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>narendra modi sir please look into bihar child...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>but he didn t trumpsworsethannixon trumpisatra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>democrats to scrutinize ex lobbyist s role in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text\n",
              "0   this is one of the worst times to be american ...\n",
              "1   how about the crowd in oval in today s ausvind...\n",
              "2   biden his son hunter took advantage of their p...\n",
              "3   etsy shop benedict donald so called president ...\n",
              "4   good build a wall around arkansas fucktrump fu...\n",
              "..                                                ...\n",
              "95  some much needed clarification after trumps un...\n",
              "96  is putin s puppet trumpsworsethannixon trumpmu...\n",
              "97  narendra modi sir please look into bihar child...\n",
              "98  but he didn t trumpsworsethannixon trumpisatra...\n",
              "99  democrats to scrutinize ex lobbyist s role in ...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz_YTdo6BFjd",
        "colab_type": "text"
      },
      "source": [
        "#ACTUAL DATA CLEANING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTVvHi5DqWBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cleaning:\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tok = WordPunctTokenizer()\n",
        "  pat1 = r'@[A-Za-z0-9]+'\n",
        "  pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "  combined_pat = r'|'.join((pat1, pat2))\n",
        "\n",
        "  def tweet_cleaner(self,text):\n",
        "      text = emoji.demojize(text)\n",
        "      soup = BeautifulSoup(text, 'lxml')\n",
        "      souped = soup.get_text()\n",
        "      stripped = re.sub(self.combined_pat, '', souped)\n",
        "      try:\n",
        "          clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "      except:\n",
        "          clean = stripped\n",
        "      letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "      letters_only = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', letters_only))\n",
        "      lower_case = letters_only.lower()\n",
        "      words = self.tok.tokenize(lower_case)\n",
        "      wordss = []\n",
        "      for w in words: \n",
        "        wordss.append(self.lemmatizer.lemmatize(w)) \n",
        "      S = (\" \".join(wordss)).strip()\n",
        "      return S\n",
        "\n",
        "  def PreProcessing(self,Data):\n",
        "      for i in range(Data.shape[0]):\n",
        "          before = Data\n",
        "          feature = Data.iloc[i,:]\n",
        "          feature = ''.join(i for i in feature if not i.isdigit())\n",
        "          exc = set(string.punctuation)\n",
        "          feature = ''.join(ch for ch in feature if ch not in exc)\n",
        "          feature = unidecode(feature)\n",
        "          feature = feature.lower()\n",
        "          feature = feature.strip()\n",
        "          feature.encode('ascii', 'ignore').decode('ascii')\n",
        "          tokenizer = RegexpTokenizer(\"\\w+|\\d\\.]+|\\S+\")\n",
        "          tokens = tokenizer.tokenize(feature)\n",
        "          New_Data = tokens\n",
        "          Data.iloc[i,:] = ' '.join([str(w) for w in New_Data])\n",
        "      return Data\n",
        "\n",
        "  def All_clean(self,Data):\n",
        "    test_result = []\n",
        "    for t in Data.text:\n",
        "      test_result.append(self.tweet_cleaner(t))\n",
        "    test_result = pd.DataFrame(test_result, columns=['text'])\n",
        "    # test_result = self.PreProcessing(test_result)\n",
        "    return test_result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myx4yPzjK-vd",
        "colab_type": "code",
        "outputId": "fd218164-221f-4f51-a4ef-1a73d8486543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "embed_num_dims = 100\n",
        "max_seq_len = 10000\n",
        "cls = cleaning()\n",
        "clean_data = cls.All_clean(df)\n",
        "print(clean_data)\n",
        "sequences = clean_data['text']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text\n",
            "0     this is one of the worst time to be american b...\n",
            "1     how about the crowd in oval in today s au sv i...\n",
            "2     biden his son hunter took advantage of their p...\n",
            "3     etsy shop benedict donald so called president ...\n",
            "4     good build a wall around arkansas fuck trump f...\n",
            "...                                                 ...\n",
            "5261  should allow m dhoni to keep glove it is attac...\n",
            "5262  trump on avoiding movie pirating of course you...\n",
            "5263  i noticed recently jamie oliver s restaurant c...\n",
            "5264  team india geared up is okay what s on the glo...\n",
            "5265  is this the same piece of paper mc carthy used...\n",
            "\n",
            "[5266 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvcLlAz6Tor8",
        "colab_type": "code",
        "outputId": "91325ee1-a9fb-4e00-cb36-6cb3f669ead1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words = 4000)\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "sequence = tokenizer.texts_to_sequences(sequences)\n",
        "index_of_words = tokenizer.word_index\n",
        "print(len(index_of_words))\n",
        "padded_seq = pad_sequences(sequence , maxlen =max_seq_len)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QouulaUATqkq",
        "colab_type": "code",
        "outputId": "c33a16d8-ef14-43b6-f857-f2e13b8d5d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(padded_seq.shape)\n",
        "Y = df['labels']\n",
        "X_train,X_test,Y_train1,Y_test1 = train_test_split(padded_seq,Y ,train_size = 0.80)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5266, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkACqbJiHgYo",
        "colab_type": "code",
        "outputId": "128547bb-d98d-4fed-c5a1-7795d07bf5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4212,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKjZhpBbRk_e",
        "colab_type": "code",
        "outputId": "1e1b6262-bf5b-4d9a-8fb6-c5da4fd1edda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/glove/glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_yqQMUQKgD",
        "colab_type": "code",
        "outputId": "e22163b1-e240-401d-d3d2-d2fc601fbbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "embeddings_index['good']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.030769 ,  0.11993  ,  0.53909  , -0.43696  , -0.73937  ,\n",
              "       -0.15345  ,  0.081126 , -0.38559  , -0.68797  , -0.41632  ,\n",
              "       -0.13183  , -0.24922  ,  0.441    ,  0.085919 ,  0.20871  ,\n",
              "       -0.063582 ,  0.062228 , -0.051234 , -0.13398  ,  1.1418   ,\n",
              "        0.036526 ,  0.49029  , -0.24567  , -0.412    ,  0.12349  ,\n",
              "        0.41336  , -0.48397  , -0.54243  , -0.27787  , -0.26015  ,\n",
              "       -0.38485  ,  0.78656  ,  0.1023   , -0.20712  ,  0.40751  ,\n",
              "        0.32026  , -0.51052  ,  0.48362  , -0.0099498, -0.38685  ,\n",
              "        0.034975 , -0.167    ,  0.4237   , -0.54164  , -0.30323  ,\n",
              "       -0.36983  ,  0.082836 , -0.52538  , -0.064531 , -1.398    ,\n",
              "       -0.14873  , -0.35327  , -0.1118   ,  1.0912   ,  0.095864 ,\n",
              "       -2.8129   ,  0.45238  ,  0.46213  ,  1.6012   , -0.20837  ,\n",
              "       -0.27377  ,  0.71197  , -1.0754   , -0.046974 ,  0.67479  ,\n",
              "       -0.065839 ,  0.75824  ,  0.39405  ,  0.15507  , -0.64719  ,\n",
              "        0.32796  , -0.031748 ,  0.52899  , -0.43886  ,  0.67405  ,\n",
              "        0.42136  , -0.11981  , -0.21777  , -0.29756  , -0.1351   ,\n",
              "        0.59898  ,  0.46529  , -0.58258  , -0.02323  , -1.5442   ,\n",
              "        0.01901  , -0.015877 ,  0.024499 , -0.58017  , -0.67659  ,\n",
              "       -0.040379 , -0.44043  ,  0.083292 ,  0.20035  , -0.75499  ,\n",
              "        0.16918  , -0.26573  , -0.52878  ,  0.17584  ,  1.065    ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3NfCWW3ThJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(index_of_words) + 1, embed_num_dims))\n",
        "\n",
        "tokens = []\n",
        "labels = []\n",
        "\n",
        "for word,i in index_of_words.items():\n",
        "    temp = embeddings_index.get(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6T0WYoaTzc1",
        "colab_type": "code",
        "outputId": "943359df-3aa7-48ba-d205-68242c5c4900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11682, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQCQhwy-T9lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedd_layer = Embedding(len(index_of_words) + 1 , embed_num_dims , input_length = max_seq_len , weights = [embedding_matrix])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmzXAsHwUFaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(embedd_layer)\n",
        "model.add(Bidirectional(LSTM(64 , return_sequences = True, dropout = 0.1 , recurrent_dropout = 0.1 )))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(32,activation = 'sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2,activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2nv2033UIpJ",
        "colab_type": "code",
        "outputId": "456f61fd-d128-48d8-9980-33a1b39e8cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 10000, 100)        1168200   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 10000, 128)        84480     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 1,256,874\n",
            "Trainable params: 1,256,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k128EDHbUNEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add = Adam(lr = 0.01)\n",
        "model.compile(loss = 'categorical_crossentropy' , optimizer = add , metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlmqgLhqUich",
        "colab_type": "code",
        "outputId": "36755d83-d48f-483e-b00c-ae1899e45d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X_train.shape,' ',Y_train1.shape,' ',X_test.shape,' ',Y_test1.shape)\n",
        "X_train = np.array(X_train).astype(np.float32)\n",
        "X_test = np.array(X_test).astype(np.float32)\n",
        "y1 = Y_train1\n",
        "y2 = Y_test1\n",
        "Y_train = to_categorical(y1,2)\n",
        "Y_test  = to_categorical(y2,2)\n",
        "print(X_train.shape,' ',Y_train.shape,' ',X_test.shape,' ',Y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4212, 10000)   (4212,)   (1054, 10000)   (1054,)\n",
            "(4212, 10000)   (4212, 2)   (1054, 10000)   (1054, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVNYs7UuRKUR",
        "colab_type": "code",
        "outputId": "d28e16a1-d7ec-404c-bd8c-ae12a9267ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "x = [63.087346,61.975683,6] \n",
        "# corresponding y axis values \n",
        "y = [1,2,3] \n",
        "  \n",
        "# plotting the points  \n",
        "plt.plot(x, y) \n",
        "  \n",
        "# naming the x axis \n",
        "plt.xlabel('hidden layers') \n",
        "# naming the y axis \n",
        "plt.ylabel('') \n",
        "  \n",
        "# giving a title to my graph \n",
        "plt.title('accuracy') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbB39eJxvZf",
        "colab_type": "code",
        "outputId": "360b9171-e8ac-412a-a22f-9e913b08b8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "hist = model.fit(X_train,Y_train,epochs = 1 , batch_size = 500, validation_data = (X_test,Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 4212 samples, validate on 1054 samples\n",
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-882949a04707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[300,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bidirectional_2/while_1/body/_251/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_7896]\n\nFunction call stack:\nkeras_scratch_graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6dfyc8jUkxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.evaluate(X_test,Y_test)\n",
        "print(result[1]*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fynjVOsOZLCn",
        "colab_type": "code",
        "outputId": "064f07b5-e126-4e1e-9260-3f746fe5d7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def prepare_submission():\n",
        "    test = pd.read_csv('/content/drive/My Drive/Data_4/f6eb0bd7-6063-4e50-baa0-111feda638fb_test.csv')\n",
        "    clean = cleaning()\n",
        "    test_data = clean.All_clean(test)\n",
        "    test_data = test_data['text']\n",
        "    tokenizer.fit_on_texts(test_data)\n",
        "    seq = tokenizer.texts_to_sequences(test_data)\n",
        "    test_final = pad_sequences(seq, maxlen = max_seq_len )\n",
        "    test_final = np.array(test_final).astype(np.float32)\n",
        "    print(test_final.shape)\n",
        "    result_final = model.predict_classes(test_final)\n",
        "    Y_data = pd.read_csv('/content/drive/My Drive/Data_4/3c41266b-1527-4f61-b489-1357bb886bb2_sample_submission.csv')\n",
        "    y_true = Y_data['labels'].values\n",
        "    return result_final,y_true.flatten()\n",
        "y_pred,y_true = prepare_submission()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(586, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbJbLxHDbChz",
        "colab_type": "code",
        "outputId": "852e70d6-54ae-44f3-dee1-5d865c35b4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "print(y_pred)\n",
        "print(y_true)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU_s0NKJdylH",
        "colab_type": "code",
        "outputId": "59c99b79-2306-4fc4-a101-12966dffc95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(pd.Series(y_true).value_counts()) \n",
        "print(pd.Series(y_pred).value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    568\n",
            "1     18\n",
            "dtype: int64\n",
            "1    423\n",
            "0    163\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHlmmzEfUjxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = pd.DataFrame(y_pred, columns=['labels'])\n",
        "y.to_csv('submission_glove.csv', header=True, index=False) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4lp7FBRLE1_",
        "colab_type": "code",
        "outputId": "7d2d25bc-dcb0-4e63-8f62-1e627aca88c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('accuracy :', accuracy_score(y_true, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.2986348122866894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hZ6bwNWJIbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = pd.read_csv('/content/submission_glove.csv')\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdlZi74keAFC",
        "colab_type": "code",
        "outputId": "73d7e9fa-6d1e-4449-aa5d-e4bb11ee4f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(A.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(586, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_GjwkKeCSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}